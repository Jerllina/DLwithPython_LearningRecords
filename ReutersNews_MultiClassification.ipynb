{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###load data\n",
    "from keras.datasets import reuters\n",
    "(train_data,train_labels),(test_data,test_labels)=reuters.load_data(num_words=10000)#the most frequent 10000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "###vectorize data\n",
    "def verorize_sequences(sequences,dimension=10000):\n",
    "    results=np.zeros((len(sequences),dimension))\n",
    "    for i,sequence in enumerate(sequences):\n",
    "        results[i,sequence]=1.\n",
    "    return results\n",
    "\n",
    "x_train=verorize_sequences(train_data)\n",
    "x_test=verorize_sequences(test_data)\n",
    "\n",
    "###vectorize labels\n",
    "def to_one_hot(labels,dimension=46):\n",
    "    results=np.zeros((len(labels),dimension))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label]=1.\n",
    "    return results\n",
    "\n",
    "one_shot_train_labels=to_one_hot(train_labels)\n",
    "one_shot_test_labels=to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###model\n",
    "from keras import models,layers\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "###compile\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 234us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7204 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 1.4450 - acc: 0.6878 - val_loss: 1.3457 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 1.0951 - acc: 0.7648 - val_loss: 1.1704 - val_acc: 0.7420\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.8695 - acc: 0.8161 - val_loss: 1.0795 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.7032 - acc: 0.8480 - val_loss: 0.9846 - val_acc: 0.7820\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.5665 - acc: 0.8795 - val_loss: 0.9409 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.4580 - acc: 0.9049 - val_loss: 0.9074 - val_acc: 0.8010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 133us/step - loss: 0.3696 - acc: 0.9228 - val_loss: 0.9349 - val_acc: 0.7900\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.3032 - acc: 0.9311 - val_loss: 0.8917 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.2538 - acc: 0.9412 - val_loss: 0.9065 - val_acc: 0.8120\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.2183 - acc: 0.9470 - val_loss: 0.9177 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.1872 - acc: 0.9509 - val_loss: 0.9022 - val_acc: 0.8160\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.1698 - acc: 0.9525 - val_loss: 0.9341 - val_acc: 0.8090\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.1531 - acc: 0.9557 - val_loss: 0.9720 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 0.1390 - acc: 0.9557 - val_loss: 0.9691 - val_acc: 0.8140\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.1312 - acc: 0.9560 - val_loss: 1.0251 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.957 - 1s 140us/step - loss: 0.1215 - acc: 0.9579 - val_loss: 1.0256 - val_acc: 0.7960\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 133us/step - loss: 0.1198 - acc: 0.9577 - val_loss: 1.0436 - val_acc: 0.8080\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.1137 - acc: 0.9594 - val_loss: 1.0935 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.1108 - acc: 0.9598 - val_loss: 1.0656 - val_acc: 0.8010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###validation\n",
    "x_val=x_train[:1000]\n",
    "partial_x_train=x_train[1000:]\n",
    "\n",
    "y_val=one_shot_train_labels[:1000]\n",
    "partial_y_train=one_shot_train_labels[1000:]\n",
    "#train 20 times\n",
    "history=model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=512,validation_data=(x_val,y_val))\n",
    "\n",
    "#plot loss function & accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain model with proper epoch\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Keras]",
   "language": "python",
   "name": "conda-env-Keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
